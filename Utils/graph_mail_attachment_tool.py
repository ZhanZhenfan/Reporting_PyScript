"""
Graph Mail Attachment Tool
---------------------------------
å°† Microsoft Graph é‚®ä»¶é™„ä»¶ä¸‹è½½é€»è¾‘å°è£…ä¸ºå¯å¤ç”¨å·¥å…·ï¼š
- æ”¯æŒ Device Code é¦–æ¬¡ç™»å½• + refresh_token ç¼“å­˜
- æŒ‰åç§°å…³é”®è¯/ç²¾ç¡®å/æ‰©å±•åç­›é€‰ã€åªå–æœ€æ–° N ä¸ª
- é™å®šè¿‘ N å¤©ã€åˆ†é¡µæ‰«æä¸Šé™
- ä¿å­˜åˆ°æŒ‡å®šç›®å½•å¹¶è¿”å›å·²ä¿å­˜æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ¥æ”¶æ—¶é—´æ–°â†’æ—§ï¼‰
- æ—¢å¯ä½œä¸ºåº“è¢« importï¼Œä¹Ÿå¯å‘½ä»¤è¡Œè°ƒç”¨

ç¤ºä¾‹ï¼ˆåº“ç”¨æ³•ï¼‰
-----------------
from graph_mail_attachment_tool import GraphMailAttachmentTool

tool = GraphMailAttachmentTool(
    tenant_id="5c2be51b-4109-461d-a0e7-521be6237ce2",
    client_id="09004044-1c60-48e5-b1eb-bb42b3892006",
)
paths = tool.download_latest_attachments(
    contains="ZMRP_WATERFALL_Run",
    ext=".xlsx",
    need_count=2,
    days_back=90,
    save_dir=r"C:\\WeeklyReport\\Download_From_Eamil",
)
print(paths)

å‘½ä»¤è¡Œï¼š
python graph_mail_attachment_tool.py \
  --tenant-id 5c2be51b-4109-461d-a0e7-521be6237ce2 \
  --client-id 09004044-1c60-48e5-b1eb-bb42b3892006 \
  --contains ZMRP_WATERFALL_Run --ext .xlsx --need-count 2 --days-back 90 \
  --save-dir "C:\\WeeklyReport\\Download_From_Eamil"
"""

from __future__ import annotations

import os
import time
import json
import base64
import datetime as dt
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List, Optional, Tuple

import requests

try:
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
except Exception:  # pragma: no cover - ç¯å¢ƒæ²¡æœ‰ urllib3 Retry ä¹Ÿèƒ½è¿è¡Œ
    HTTPAdapter = None
    Retry = None


# =========================
# å·¥å…·ç±»å°è£…
# =========================
@dataclass
class AuthConfig:
    tenant_id: str
    client_id: str
    scopes: str = "Mail.Read offline_access"
    token_cache: str = "graph_token_cache.json"


class GraphMailAttachmentTool:
    """Microsoft Graph é‚®ä»¶é™„ä»¶ä¸‹è½½å™¨ï¼ˆå¸¦ Token ç¼“å­˜ï¼‰ã€‚"""

    GRAPH_BASE = "https://graph.microsoft.com/v1.0"

    def __init__(self, tenant_id: str, client_id: str, *,
                 scopes: str = "Mail.Read offline_access",
                 token_cache: str = "graph_token_cache.json",
                 session: Optional[requests.Session] = None,
                 request_timeout: int = 60):
        self.auth = AuthConfig(tenant_id=tenant_id, client_id=client_id,
                               scopes=scopes, token_cache=token_cache)
        self.request_timeout = int(request_timeout)

        # AAD endpoints
        self.auth_base = f"https://login.microsoftonline.com/{self.auth.tenant_id}/oauth2/v2.0"
        self.device_code_url = f"{self.auth_base}/devicecode"
        self.token_url = f"{self.auth_base}/token"

        # HTTP sessionï¼ˆå¸¦é‡è¯•ï¼‰
        self.session = session or self._build_session()

    # ---------- Session & helpers ----------
    def _build_session(self) -> requests.Session:
        s = requests.Session()
        s.headers.update({
            "User-Agent": "GraphMailAttachmentTool/1.0 (+https://microsoft.com/graph)",
        })
        if HTTPAdapter and Retry:
            retry = Retry(
                total=5,
                backoff_factor=0.6,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=["GET", "POST"],
            )
            adapter = HTTPAdapter(max_retries=retry)
            s.mount("https://", adapter)
            s.mount("http://", adapter)
        return s

    @staticmethod
    def _now() -> int:
        return int(time.time())

    def _load_tok(self) -> Optional[dict]:
        p = Path(self.auth.token_cache)
        if not p.exists():
            return None
        try:
            return json.loads(p.read_text("utf-8"))
        except Exception:
            return None

    def _save_tok(self, tok: dict) -> None:
        Path(self.auth.token_cache).write_text(
            json.dumps(tok, ensure_ascii=False, indent=2), encoding="utf-8"
        )

    @staticmethod
    def _valid(tok: Optional[dict], skew: int = 60) -> bool:
        return bool(tok and "access_token" in tok and tok.get("expires_at", 0) - GraphMailAttachmentTool._now() > skew)

    def _refresh(self, tok: Optional[dict]) -> Optional[dict]:
        if not tok or "refresh_token" not in tok:
            return None
        r = self.session.post(self.token_url, data={
            "grant_type": "refresh_token",
            "client_id": self.auth.client_id,
            "refresh_token": tok["refresh_token"],
            "scope": self.auth.scopes,
        }, timeout=self.request_timeout)
        if r.status_code != 200:
            return None
        d = r.json()
        d["expires_at"] = self._now() + int(d.get("expires_in", 3600))
        # æœ‰äº›æƒ…å†µä¸‹è¿”å›ä¸ä¼šæºå¸¦æ–°çš„ refresh_tokenï¼Œéœ€ä¿ç•™æ—§çš„
        d.setdefault("refresh_token", tok.get("refresh_token"))
        self._save_tok(d)
        return d

    def _device_login(self) -> dict:
        dc = self.session.post(self.device_code_url, data={
            "client_id": self.auth.client_id,
            "scope": self.auth.scopes,
        }, timeout=self.request_timeout).json()
        print("[LOGIN] æ‰“å¼€ç½‘å€å¹¶è¾“å…¥éªŒè¯ç å®Œæˆæˆæƒ / Open the URL and enter the code to authorize:")
        print("         URL:", dc.get("verification_uri"))
        print("         CODE:", dc.get("user_code"))
        print("         ç­‰å¾…ä½ å®Œæˆç™»å½•... / Waiting for you to finish sign-in...")
        start = time.time()
        while True:
            if time.time() - start > dc["expires_in"]:
                raise RuntimeError("Device code å·²è¿‡æœŸï¼Œè¯·é‡è¯•è¿è¡Œ / Device code expired, please rerun.")
            r = self.session.post(self.token_url, data={
                "grant_type": "urn:ietf:params:oauth:grant-type:device_code",
                "client_id": self.auth.client_id,
                "device_code": dc["device_code"],
            }, timeout=self.request_timeout)
            d = r.json()
            if "access_token" in d:
                d["expires_at"] = self._now() + int(d.get("expires_in", 3600))
                self._save_tok(d)
                print("[LOGIN] âœ… é¦–æ¬¡æˆæƒæˆåŠŸï¼Œå·²è·å– Access Token / First authorization succeeded; access token obtained")
                return d
            if d.get("error") in ("authorization_pending", "slow_down"):
                time.sleep(dc.get("interval", 5))
                continue
            raise RuntimeError(f"Token error: {d}")

    def get_access_token(self) -> str:
        tok = self._load_tok()
        if self._valid(tok):
            return tok["access_token"]
        tok2 = self._refresh(tok)
        if tok2 and "access_token" in tok2:
            print("[LOGIN] ğŸ”„ å·²åˆ·æ–° Access Token / Access token refreshed")
            return tok2["access_token"]
        tok3 = self._device_login()
        return tok3["access_token"]

    # ---------- HTTP wrappers ----------
    def _gget(self, url: str, token: str, params: Optional[dict] = None) -> dict:
        r = self.session.get(url, headers={"Authorization": f"Bearer {token}"}, params=params, timeout=self.request_timeout)
        if r.status_code >= 400:
            msg = f"{r.status_code} GET {url}\n{r.text[:500]}"
            raise requests.HTTPError(msg)
        return r.json()

    def _download_value(self, url: str, token: str) -> bytes:
        r = self.session.get(url, headers={"Authorization": f"Bearer {token}"}, timeout=max(180, self.request_timeout))
        r.raise_for_status()
        return r.content

    # ---------- Utilities ----------
    @staticmethod
    def _iso_utc_minus_days(days: int) -> str:
        t = dt.datetime.now(dt.timezone.utc) - dt.timedelta(days=max(0, int(days)))
        return t.isoformat(timespec="seconds").replace("+00:00", "Z")

    @staticmethod
    def _parse_graph_dt(s: str) -> dt.datetime:
        if not s:
            return dt.datetime.min.replace(tzinfo=dt.timezone.utc)
        if s.endswith("Z"):
            s = s.replace("Z", "+00:00")
        return dt.datetime.fromisoformat(s)

    @staticmethod
    def _safe_name(n: str) -> str:
        return "".join(ch for ch in n if ch not in '\\/:*?"<>|')

    # ---------- Public API ----------
    def download_latest_attachments(
        self,
        *,
        contains: Optional[str] = None,
        equals: Optional[str] = None,
        ext: Optional[str] = None,
        need_count: int = 2,
        days_back: int = 90,
        page_size: int = 50,
        max_scan: int = 800,
        save_dir: str | os.PathLike = ".",
        mail_folder: Optional[str] = None,  # e.g. "inbox"ï¼›é»˜è®¤æ‰€æœ‰æ–‡ä»¶å¤¹
    ) -> List[Path]:
        """
        ä¸‹è½½ç¬¦åˆç­›é€‰æ¡ä»¶çš„æœ€æ–° N ä¸ªé™„ä»¶ï¼Œå¹¶è¿”å›ä¿å­˜è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ¥æ”¶æ—¶é—´æ–°â†’æ—§ï¼‰ã€‚

        :param contains: æ–‡ä»¶ååŒ…å«å…³é”®å­—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ã€‚
        :param equals:   æ–‡ä»¶åç²¾ç¡®ç­‰äºï¼ˆä¼˜å…ˆçº§é«˜äº containsï¼‰ã€‚
        :param ext:      æ‰©å±•åï¼ˆå¦‚ ".xlsx"ï¼‰ï¼Œè‹¥æä¾›åˆ™æŒ‰åç¼€è¿‡æ»¤ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ã€‚
        :param need_count: éœ€è¦ä¸‹è½½çš„é™„ä»¶ä¸ªæ•°ï¼ˆé»˜è®¤ 2ï¼‰ã€‚
        :param days_back:  ä»…è€ƒè™‘æœ€è¿‘ N å¤©é‚®ä»¶ï¼ˆé»˜è®¤ 90ï¼‰ã€‚
        :param page_size:  æ¯é¡µæŠ“å–é‚®ä»¶æ•°ï¼ˆé»˜è®¤ 50ï¼‰ã€‚
        :param max_scan:   æœ€å¤šæ‰«æçš„é‚®ä»¶æ•°ï¼ˆé»˜è®¤ 800ï¼‰ã€‚
        :param save_dir:   ä¿å­˜ç›®å½•ï¼ˆä¸å­˜åœ¨å°†è‡ªåŠ¨åˆ›å»ºï¼‰ã€‚
        :param mail_folder:æŒ‡å®šé‚®ä»¶å¤¹ï¼ˆå¦‚ "inbox"ï¼‰ï¼Œä¸ä¼ åˆ™æ‰«ææ‰€æœ‰æ–‡ä»¶å¤¹ã€‚
        :return:           List[Path] å·²ä¿å­˜æ–‡ä»¶è·¯å¾„ï¼ŒæŒ‰é‚®ä»¶æ¥æ”¶æ—¶é—´é™åºã€‚
        """
        save_path = Path(save_dir)
        save_path.mkdir(parents=True, exist_ok=True)

        token = self.get_access_token()
        since_iso = self._iso_utc_minus_days(days_back)
        since_dt = self._parse_graph_dt(since_iso)

        # Messages endpointï¼ˆå¯é€‰é™å®šåˆ°æŸä¸ªæ–‡ä»¶å¤¹ï¼‰
        if mail_folder:
            messages_url = f"{self.GRAPH_BASE}/me/mailFolders/{mail_folder}/messages"
        else:
            messages_url = f"{self.GRAPH_BASE}/me/messages"

        params = {
            "$select": "id,subject,receivedDateTime,hasAttachments",
            "$orderby": "receivedDateTime desc",
            "$top": str(int(page_size)),
        }

        def _name_match(name: str) -> bool:
            low = (name or "").lower()
            if equals:
                return name == equals
            ok = True
            if contains:
                ok = (contains.lower() in low)
            if ok and ext:
                ok = low.endswith(ext.lower())
            return ok

        saved: List[Tuple[dt.datetime, Path]] = []
        found = scanned = 0
        url = messages_url
        local_params = params
        while url and scanned < max_scan and found < need_count:
            data = self._gget(url, token, params=local_params)
            local_params = None  # nextLink å·²ç»åŒ…å«åˆ†é¡µå‚æ•°
            msgs = data.get("value", [])
            if not msgs:
                break

            for m in msgs:
                scanned += 1
                rdt_str = m.get("receivedDateTime") or ""
                if not rdt_str:
                    continue
                rdt = self._parse_graph_dt(rdt_str)
                if rdt < since_dt:
                    url = None  # æ—¶é—´æ›´è€ï¼Œæ— éœ€ç»§ç»­åˆ†é¡µ
                    break
                if not m.get("hasAttachments"):
                    continue

                mid = m["id"]
                # è¯»å–é™„ä»¶å…ƒæ•°æ®
                atts = self._gget(f"{self.GRAPH_BASE}/me/messages/{mid}/attachments", token)
                for a in atts.get("value", []):
                    if a.get("isInline"):
                        continue
                    otype = a.get("@odata.type", "")
                    if otype and not otype.endswith("fileAttachment"):
                        continue

                    name = a.get("name") or "attachment.bin"
                    if not _name_match(name):
                        continue

                    # ä»¥é‚®ä»¶æ¥æ”¶æ—¶é—´æˆ³é‡å‘½å
                    ts = rdt_str.replace(":", "").replace("-", "")[:15]  # e.g. 20250921T103000
                    safe = self._safe_name(name)
                    base, extname = os.path.splitext(safe)
                    filepath = save_path / f"{base}_{ts}{extname}"

                    # ä¸‹è½½å†…å®¹ï¼šä¼˜å…ˆ contentBytesï¼Œå¦åˆ™ $value
                    content_b64 = a.get("contentBytes")
                    if content_b64:
                        content = base64.b64decode(content_b64)
                    else:
                        att_id = a["id"]
                        content = self._download_value(
                            f"{self.GRAPH_BASE}/me/messages/{mid}/attachments/{att_id}/$value",
                            token,
                        )

                    filepath.write_bytes(content)
                    print(f"[SAVE] {filepath}")
                    saved.append((rdt, filepath))
                    found += 1
                    if found >= need_count:
                        break
                if found >= need_count or scanned >= max_scan:
                    break
            url = data.get("@odata.nextLink")

        # æŒ‰æ—¶é—´æ’åºï¼ˆæ–°â†’æ—§ï¼‰ï¼Œä»…è¿”å›è·¯å¾„
        saved.sort(key=lambda t: t[0], reverse=True)
        out_paths = [p for _, p in saved][:need_count]

        if not out_paths:
            print("[WARN] æœªæ‰¾åˆ°åŒ¹é…é™„ä»¶ã€‚è¯·æ£€æŸ¥å…³é”®è¯/æ‰©å±•åæˆ–å¢å¤§ days_backã€‚"
                  " / No matching attachments found. Check keywords/extensions or increase days_back.")
        else:
            print(f"[OK] ä¸‹è½½å®Œæˆï¼Œå…± {len(out_paths)} ä¸ªã€‚ç›®å½•: {save_path.resolve()} / "
                  f"Download complete, total {len(out_paths)}. Folder: {save_path.resolve()}")
        return out_paths


# =========================
# CLI å…¥å£
# =========================
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Download latest matching attachments via Microsoft Graph (with token cache)."
    )
    parser.add_argument("--tenant-id", required=True)
    parser.add_argument("--client-id", required=True)
    parser.add_argument("--contains", default=None, help="æ–‡ä»¶ååŒ…å«å…³é”®å­—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰")
    parser.add_argument("--equals", default=None, help="æ–‡ä»¶åç²¾ç¡®ç­‰äºï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰")
    parser.add_argument("--ext", default=None, help="æ‰©å±•åè¿‡æ»¤ï¼Œå¦‚ .xlsx")
    parser.add_argument("--need-count", type=int, default=2)
    parser.add_argument("--days-back", type=int, default=90)
    parser.add_argument("--page-size", type=int, default=50)
    parser.add_argument("--max-scan", type=int, default=800)
    parser.add_argument("--save-dir", default=".")
    parser.add_argument("--token-cache", default="graph_token_cache.json")
    parser.add_argument("--mail-folder", default=None, help="æŒ‡å®šæ–‡ä»¶å¤¹ï¼ˆå¦‚ inboxï¼‰ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰æ–‡ä»¶å¤¹")
    parser.add_argument("--timeout", type=int, default=60, help="è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")

    args = parser.parse_args()

    tool = GraphMailAttachmentTool(
        tenant_id=args.tenant_id,
        client_id=args.client_id,
        scopes="Mail.Read offline_access",
        token_cache=args.token_cache,
        request_timeout=args.timeout,
    )

    tool.download_latest_attachments(
        contains=args.contains,
        equals=args.equals,
        ext=args.ext,
        need_count=args.need_count,
        days_back=args.days_back,
        page_size=args.page_size,
        max_scan=args.max_scan,
        save_dir=args.save_dir,
        mail_folder=args.mail_folder,
    )
